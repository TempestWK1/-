##1.特征工程基本流程
- **目的**
筛选出更好的特征，获取更好的训练数据
###数据采集 / 清洗 / 采样
- **数据采样**
采集、清洗过数据以后，正负样本是不均衡的，要进行数据采样。采样的方法有随机采样和分层抽样。但是随机采样会有隐患，因为可能某次随机采样得到的数据很不均匀，更多的是根据特征采用分层抽样。
正样本 >> 负样本，且量都挺大 => downsampling
正样本 >> 负样本，量不大 => 
1）采集更多的数据
2）上采样/oversampling(比如图像识别中的镜像和旋转) 
3）修改损失函数/loss function (设置样本权重)
###特征处理
- **数值型**
幅度调整/归一化
统计值：包括max, min, mean, std等
离散化：把连续值转成非线性数据
- **类别型**
类别型一般是文本信息
1）one-hot编码，编码后得到哑变量
2）Hash编码成词向量
3）Histogram映射：把每一列的特征拿出来，根据target内容做统计，把target中的每个内容对应的百分比填到对应的向量的位置。
- **文本型**
1）词袋：文本数据预处理后，去掉停用词，剩下的词组成的list，在词库中的映射稀疏向量。
2）把词袋中的词扩充到n-gram
3）使用TF-IDF特征：TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度
###特征选择
特征选择，就是从多个特征中，挑选出一些对结果预测最有用的特征。因为原始的特征中可能会有冗余和噪声。
- **过滤型**
*方法*：评估单个特征和结果值之间的相关程度， 排序留下Top相关的特征部分。 
*方式*：Pearson相关系数， 互信息， 距离相关度
*缺点*：只评估了单个特征对结果的影响，没有考虑到特征之间的关联作用， 可能把有用的关联特征误踢掉。因此工业界使用比较少。 
- **包裹型**
*方法*：把特征选择看做一个特征子集搜索问题， 筛选各种特征子集， 用模型评估效果。 
*典型算法*：“递归特征删除算法”。 
*应用在逻辑回归的过程*：用全量特征跑一个模型；根据线性模型的系数(体现相关性)，删掉5-10%的弱特征，观察准确率/auc的变化；逐步进行， 直至准确率/auc出现大的下滑停止。 
- **嵌入型**
*方法*：根据模型来分析特征的重要性，最常见的方式为用正则化方式来做特征选择。
*举例*：最早在电商用LR做CTR预估， 在3-5亿维的系数特征上用L1正则化的LR模型。