在线性回归模型中，通常有两种不同的正则化项：
加上所有参数（不包括θ0）的绝对值之和，即l1范数，此时叫做Lasso回归；
加上所有参数（不包括θ0）的平方和，即l2范数，此时叫做岭回归.


## Dropout的正则化原理
- 随机删除网络中的一些隐藏神经元，保持输入输出神经元不变
- 将输入通过修改后的网络进行前向传播，然后将误差通过修改后的网络进行反向传播
- 对于另外一批的训练样本，重复上述操作

 Dropout相当于模型平均、模型组合