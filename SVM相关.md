# SVM
SVM是一种有监督的统计学习方法，能够最小化经验误差和最大化几何边缘，被称为最大间隔分类器，可用于分类和回归分析。

提供了一种避开高维空间的复杂性，直接使用此空间上的内积函数（核函数），再利用在线性可分的情况下的求解方法直接求解对应的高维空间的决策问题

## SVM的对偶问题
通过求解与原问题等价的对偶问题（dual problem）得到原始问题的最优解，这就是线性可分条件下支持向量机的对偶算法，这样做的优点在于：一者对偶问题往往更容易求解；二者可以自然的引入核函数，进而推广到非线性分类问题。

## 合页损失函数(Hinge Loss)
针对原问题

## 优缺点
##### SVM算法的优点
- 可以解决小样本情况下的机器学习问题；
- 可以提高泛化性能；
- 可以处理高维空间数据；
- 可以解决非线性问题。
##### SVM算法的缺点
- 对于线性问题没有通用的解决方案，必须谨慎选择核函数；
- 在选择合适的核函数之后，在处理分类问题时，要求解函数的二次规划，而在这过程中，需要大量的存储空间